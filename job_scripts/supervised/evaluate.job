#!/bin/bash

#SBATCH -N 1 # number of nodes
#SBATCH --partition=gpu_titanrtx_shared
#SBATCH --job-name=sup_eval
#SBATCH --gpus-per-node=titanrtx:1
#SBATCH --time=00:30:00
#SBATCH --output=temp_logs/slurm_output_%j.out

LOGS_DIR=/project/bdolicki/logs
CHECKPOINT_DIR=$LOGS_DIR/supervised/$SLURM_JOB_NAME/$SLURM_JOB_ID

module load 2021
module load Anaconda3/2021.05

source activate e2cnn
cd $HOME/thesis/ssl-histo/
mkdir -p $CHECKPOINT_DIR

DATA_DIR=$HOME"/thesis/ssl-histo/data/pcam"

python evaluate.py --dataset pcam --data_dir $DATA_DIR --split test --log_dir $CHECKPOINT_DIR \
                --checkpoint_path /project/bdolicki/logs/supervised/pcam_multigpu/8984348/checkpoints/model_epoch_14.pt \
                --batch_size=128 --num_workers=1

echo "finished"

# move slurm output from default location to logs after the job is finished
mv $HOME/thesis/ssl-histo/temp_logs/slurm_output_$SLURM_JOB_ID.out $CHECKPOINT_DIR/