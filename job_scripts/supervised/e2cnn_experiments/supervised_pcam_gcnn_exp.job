#!/bin/bash

#SBATCH -N 1 # number of nodes
#SBATCH --partition=gpu_titanrtx
#SBATCH --job-name=sup_pcam_gcnn_exp
#SBATCH --gpus-per-node=titanrtx:1
#SBATCH --time=01:00:00
#SBATCH --output=temp_logs/slurm_output_%j.out


LOGS_DIR=/project/bdolicki/logs
CHECKPOINT_DIR=$LOGS_DIR/supervised/$SLURM_JOB_NAME/$SLURM_JOB_ID
RUN_NAME=${SLURM_JOB_NAME}_${SLURM_JOB_ID}

module load 2021
module load Anaconda3/2021.05

source activate e2cnn
cd $HOME/thesis/e2cnn_experiments/experiments

python multiple_exps.py --batch_size=32 --worker=8 --dataset=pcam --model=EXP --type=regular --N=8 --restrict=0 \
                        --F=None --sigma=None --interpolation=2 --epochs=1 --lr=0.001  --augment --verbose=4 \
                        --adapt_lr=exponential --lr_decay_start=10 --reshuffle --weight_decay=0.0 --optimizer=sfcnn \
                        --lamb_fully_L2=0.0000001  --lamb_conv_L2=0.0000001 --lamb_bn_L2=0 --lamb_softmax_L2=0 \
                        --fixparams --S 1 --log_dir $CHECKPOINT_DIR --profile

echo "finished"

# move slurm output from default location to logs after the job is finished
mkdir -p $CHECKPOINT_DIR
mv $HOME/thesis/ssl-histo/temp_logs/slurm_output_$SLURM_JOB_ID.out $CHECKPOINT_DIR/
