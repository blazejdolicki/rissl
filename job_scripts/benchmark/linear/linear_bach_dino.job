#!/bin/bash
#SBATCH -N 1 # number of nodes
#SBATCH -p gpu_titanrtx
#SBATCH --gpus-per-node=titanrtx:4 # use all 4 GPUs in the node
#SBATCH --job-name=linear_bach_dino
#SBATCH -t 08:00:00
#SBATCH --output=temp_logs/slurm_output_%j.out

NUM_WORKERS=2
NUM_GPUS=1
NUM_TASKS=1
NUM_MACHINES=1
TRAIN=train/
SOURCE=$HOME/thesis/hissl
SINGULARITYIMAGE=$HOME/thesis/hissl_20210922_np121_h5py.sif
CONFIG_PATH=blazej/benchmark/linear
LOGS_DIR=/project/bdolicki/logs
CHECKPOINT_DIR=$LOGS_DIR/$SLURM_JOB_NAME/$SLURM_JOB_ID
DATA_ROOT=$HOME"/thesis/ssl-histo/data/bach"
MODEL_WEIGHTS=$LOGS_DIR"/train_nct_dino/8521997/model_phase40.torch"

run_train()
{
  echo "python3 tools/run_distributed_engines_hissl.py \
    hydra.verbose=true \
    config=$CONFIG_PATH/linear_dino \
    +config/$CONFIG_PATH=bach_head.yaml \
    config.DATA.TRAIN.DATASET_NAMES=[bach] \
    config.DATA.TRAIN.DATA_PATHS=[\"$DATA_ROOT/train_images_fold$fold.npy\"] \
    config.DATA.TRAIN.LABEL_PATHS=[\"$DATA_ROOT/train_labels_fold$fold.npy\"] \
    config.DATA.TRAIN.DATA_SOURCES=[disk_filelist] \
    config.DATA.TRAIN.LABEL_SOURCES=[disk_filelist] \
    config.DATA.TEST.DATASET_NAMES=[bach] \
    config.DATA.TEST.DATA_PATHS=[\"$DATA_ROOT/val_images_fold$fold.npy\"] \
    config.DATA.TEST.LABEL_PATHS=[\"$DATA_ROOT/val_labels_fold$fold.npy\"] \
    config.DATA.TEST.DATA_SOURCES=[disk_filelist] \
    config.DATA.TEST.LABEL_SOURCES=[disk_filelist] \
    config.CHECKPOINT.DIR=$CHECKPOINT_DIR/fold$fold \
    config.OPTIMIZER.num_epochs=100 \
    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=$MODEL_WEIGHTS"
}

slurm_submit()
{
  SINGULARITYENV_VISSL_DATASET_CATALOG_PATH=/hissl/custom_catalog.json singularity exec --no-home --nv \
      --bind $SOURCE:/hissl \
      --bind $HOME/thesis/ssl-histo/config/blazej:/hissl/configs/config/blazej \
      --bind $LOGS_DIR \
      --bind $DATA_ROOT \
      --pwd /hissl \
      $SINGULARITYIMAGE \
      $COMMAND &
}

cd $SOURCE

# for multi-machine GPUs: stops the job in case of NCCL ASYNC errors
export NCCL_ASYNC_ERROR_HANDLING=1
export NCCL_DEBUG=INFO

# to silence this error:
# "ERROR: ld.so: object '/sara/tools/xalt/xalt/lib64/libxalt_init.so'
# from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored."
unset LD_PRELOAD

k=5
for (( fold=0; fold<$k; fold++ ))
do
  echo $fold
	COMMAND=$(run_train $fold)
  echo $(slurm_submit $COMMAND)
done

module load 2021
module load Anaconda3/2021.05


# concatenate results
python $HOME/thesis/ssl-histo/utils/aggregate_fold_results.py -e $CHECKPOINT_DIR

# move slurm output from default location to logs after the job is finished
mv ../ssl-histo/temp_logs/slurm_output_$SLURM_JOB_ID.out $CHECKPOINT_DIR/