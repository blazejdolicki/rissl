#!/bin/bash
#SBATCH -N 1 # number of nodes
#SBATCH -p gpu_titanrtx
#SBATCH --gpus-per-node=titanrtx:1 # use all 4 GPUs in the node
#SBATCH --job-name=linear_bach_dino
#SBATCH -t 08:00:00
#SBATCH --output=temp_logs/slurm_output_%j.out

SOURCE=$HOME/thesis/hissl
SINGULARITYIMAGE=$HOME/thesis/hissl_20210922_np121_h5py.sif
CONFIG_PATH=blazej/benchmark/linear
LOGS_DIR=/project/bdolicki/logs
CHECKPOINT_DIR=$LOGS_DIR/benchmark/linear/$SLURM_JOB_NAME/$SLURM_JOB_ID
DATA_HOME_DIR=$HOME"/thesis/ssl-histo/data/bach"
DATA_SCRATCH_DIR="$TMPDIR"/"data/bach"
MODEL_WEIGHTS=$LOGS_DIR"/train_nct_dino/8521997/model_phase40.torch"

# Copy data to scratch
mkdir -p $DATA_SCRATCH_DIR
start_time=$(date '+%B %V %T')
echo "${start_time}:Copying data from $DATA_HOME_DIR to scratch..."

# Note: If the source directory has a trailing slash, rsync will copy only the directory
# contents to the destination directory. When the trailing slash is omitted, rsync copies the source
# directory inside the destination directory.

rsync -az $DATA_HOME_DIR/ $DATA_SCRATCH_DIR # add -v option for verbose
end_time=$(date '+%B %V %T')
echo "${end_time}: Finished copying data to scratch..."

REMOVE_IMG_PATH_PREFIX=$DATA_HOME_DIR
NEW_IMG_PATH_PREFIX=$DATA_SCRATCH_DIR

run_train()
{
  echo "python3 tools/run_distributed_engines_hissl.py \
    hydra.verbose=true \
    config=$CONFIG_PATH/linear_dino \
    +config/$CONFIG_PATH=bach_head.yaml \
    config.DATA.TRAIN.DATASET_NAMES=[bach] \
    config.DATA.TRAIN.DATA_PATHS=[\"$DATA_SCRATCH_DIR/train_images_fold$fold.npy\"] \
    config.DATA.TRAIN.LABEL_PATHS=[\"$DATA_SCRATCH_DIR/train_labels_fold$fold.npy\"] \
    config.DATA.TRAIN.DATA_SOURCES=[disk_filelist] \
    config.DATA.TRAIN.LABEL_SOURCES=[disk_filelist] \
    config.DATA.TRAIN.REMOVE_IMG_PATH_PREFIX=$REMOVE_IMG_PATH_PREFIX \
    config.DATA.TRAIN.NEW_IMG_PATH_PREFIX=$NEW_IMG_PATH_PREFIX
    config.DATA.TEST.DATASET_NAMES=[bach] \
    config.DATA.TEST.DATA_PATHS=[\"$DATA_SCRATCH_DIR/val_images_fold$fold.npy\"] \
    config.DATA.TEST.LABEL_PATHS=[\"$DATA_SCRATCH_DIR/val_labels_fold$fold.npy\"] \
    config.DATA.TEST.DATA_SOURCES=[disk_filelist] \
    config.DATA.TEST.LABEL_SOURCES=[disk_filelist] \
    config.DATA.TEST.REMOVE_IMG_PATH_PREFIX=$REMOVE_IMG_PATH_PREFIX \
    config.DATA.TEST.NEW_IMG_PATH_PREFIX=$NEW_IMG_PATH_PREFIX
    config.CHECKPOINT.DIR=$CHECKPOINT_DIR/fold$fold \
    config.OPTIMIZER.num_epochs=1 \
    config.MODEL.WEIGHTS_INIT.PARAMS_FILE=$MODEL_WEIGHTS
    config.DISTRIBUTED.NUM_PROC_PER_NODE=1" # TODO change when GPUs fixed
}

slurm_submit()
{
  SINGULARITYENV_VISSL_DATASET_CATALOG_PATH=/hissl/custom_catalog.json singularity exec --no-home --nv \
      --bind $SOURCE:/hissl \
      --bind $HOME/thesis/ssl-histo/config/blazej:/hissl/configs/config/blazej \
      --bind $LOGS_DIR \
      --bind "$TMPDIR" \
      --pwd /hissl \
      $SINGULARITYIMAGE \
      $COMMAND &
}

cd $SOURCE

# for multi-machine GPUs: stops the job in case of NCCL ASYNC errors
export NCCL_ASYNC_ERROR_HANDLING=1
export NCCL_DEBUG=INFO

# to silence this error:
# "ERROR: ld.so: object '/sara/tools/xalt/xalt/lib64/libxalt_init.so'
# from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored."
unset LD_PRELOAD

k=5
for (( fold=0; fold<$k; fold++ ))
do
  echo $fold
	COMMAND=$(run_train $fold)
  echo $(slurm_submit $COMMAND)
done

module load 2021
module load Anaconda3/2021.05


# concatenate results
python $HOME/thesis/ssl-histo/tools/aggregate_fold_results.py -e $CHECKPOINT_DIR

# move slurm output from default location to logs after the job is finished
mv ../ssl-histo/temp_logs/slurm_output_$SLURM_JOB_ID.out $CHECKPOINT_DIR/